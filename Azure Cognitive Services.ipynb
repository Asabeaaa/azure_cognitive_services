{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics\n",
      "  Downloading azure_ai_textanalytics-5.0.0-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.26-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied, skipping upgrade: azure-core<2.0.0,>=1.4.0 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from azure-ai-textanalytics) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: msrest>=0.6.0 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from azure-ai-textanalytics) (0.6.18)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.6 in c:\\users\\annie\\appdata\\roaming\\python\\python38\\site-packages (from azure-ai-textanalytics) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.18.4 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from msrest>=0.6.0->azure-ai-textanalytics) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from msrest>=0.6.0->azure-ai-textanalytics) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from msrest>=0.6.0->azure-ai-textanalytics) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\annie\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.0->azure-ai-textanalytics) (3.1.0)\n",
      "Installing collected packages: azure-common, azure-ai-textanalytics\n",
      "Successfully installed azure-ai-textanalytics-5.0.0 azure-common-1.1.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade azure-ai-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"31179c8b00bb46a6b4a4f849040a####\"\n",
    "endpoint = \"https://shujaaztextanalytics.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential) \n",
    "    return text_analytics_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"I had the best day of my life. I wish you were there with me.\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: positive\n",
      "Overall scores: positive=1.00; neutral=0.00; negative=0.00 \n",
      "\n",
      "Sentence: I had the best day of my life.\n",
      "Sentence 1 sentiment: positive\n",
      "Sentence score:\n",
      "Positive=1.00\n",
      "Neutral=0.00\n",
      "Negative=0.00\n",
      "\n",
      "Sentence: I wish you were there with me.\n",
      "Sentence 2 sentiment: neutral\n",
      "Sentence score:\n",
      "Positive=0.21\n",
      "Neutral=0.77\n",
      "Negative=0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"Hapana\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: neutral\n",
      "Overall scores: positive=0.13; neutral=0.82; negative=0.05 \n",
      "\n",
      "Sentence: Hapana\n",
      "Sentence 1 sentiment: neutral\n",
      "Sentence score:\n",
      "Positive=0.13\n",
      "Neutral=0.82\n",
      "Negative=0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"Nakubali Kabisa\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: neutral\n",
      "Overall scores: positive=0.07; neutral=0.90; negative=0.03 \n",
      "\n",
      "Sentence: Nakubali Kabisa\n",
      "Sentence 1 sentiment: neutral\n",
      "Sentence score:\n",
      "Positive=0.07\n",
      "Neutral=0.90\n",
      "Negative=0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"Zii Niko tu fine\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.93; neutral=0.01; negative=0.06 \n",
      "\n",
      "Sentence: Zii Niko tu fine\n",
      "Sentence 1 sentiment: positive\n",
      "Sentence score:\n",
      "Positive=0.93\n",
      "Neutral=0.01\n",
      "Negative=0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"Nitaongeza stock\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: neutral\n",
      "Overall scores: positive=0.13; neutral=0.84; negative=0.03 \n",
      "\n",
      "Sentence: Nitaongeza stock\n",
      "Sentence 1 sentiment: neutral\n",
      "Sentence score:\n",
      "Positive=0.13\n",
      "Neutral=0.84\n",
      "Negative=0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Bonjour\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  French\n"
     ]
    }
   ],
   "source": [
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Zii Niko tu fine\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  Italian\n"
     ]
    }
   ],
   "source": [
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Hapana\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  Swahili\n"
     ]
    }
   ],
   "source": [
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Nakubali Kabisa\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  Swahili\n"
     ]
    }
   ],
   "source": [
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Add stock ya viatu\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  Swahili\n"
     ]
    }
   ],
   "source": [
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_phrase_extraction_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"Zii Niko tu fine\"]\n",
    "\n",
    "        response = client.extract_key_phrases(documents = documents)[0]\n",
    "\n",
    "        if not response.is_error:\n",
    "            print(\"\\tKey Phrases:\")\n",
    "            for phrase in response.key_phrases:\n",
    "                print(\"\\t\\t\", phrase)\n",
    "        else:\n",
    "            print(response.id, response.error)\n",
    " \n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKey Phrases:\n",
      "\t\t Zii Niko tu\n"
     ]
    }
   ],
   "source": [
    "key_phrase_extraction_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = 'eeee13bcfa3844c790116b963f9f642a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation(text_input, language_output):\n",
    "    base_url = 'https://api-eur.cognitive.microsofttranslator.com'\n",
    "    path = '/translate?api-version=3.0'\n",
    "    params = '&to=' + language_output\n",
    "    constructed_url = base_url + path + params\n",
    "\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "        'Ocp-Apim-Subscription-Region': 'westeurope',\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "\n",
    "    # You can pass more than one object in body.\n",
    "    body = [{\n",
    "        'text' : text_input\n",
    "    }]\n",
    "    response = requests.post(constructed_url, headers=headers, json=body)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
